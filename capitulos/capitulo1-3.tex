\section{Matriz asociada a una transformación lineal}

Hemos visto que para cualquier espacio vectorial podemos crear un sistema de coordenadas a partir de una base ordenada, esto nos permite trabajar con los elementos del espacio de una forma más simple. El siguiente paso es poder hacer lo mismo con las transformaciones lineales.

Sabemos que dada una matriz $M$ de $m \times n$ entonces la función $T_M \colon \F^n \to \F^m$ dada por $T(v) = Mv$  es una transformación lineal, a la cual llamaremos la transformación \emph{inducida} por $M$. Ahora, buscamos hacer el mismo proceso pero de manera inversa, es decir, si consideremos dos $\F$-espacios vectoriales $V$ y $W$ con bases ordenadas $B = (v_1,\ldots,v_n)$ y $B' = (w_1,\ldots,w_m)$, respectivamente, si $T\colon V \to W$ es una transformación lineal, lo que buscamos es una matriz $M$ de tamaño $m\times n$ tal que $M[v]_B = [T(v)]_{B'}$, para todo $v \in V$. A esta matriz la denotaremos como $T_{B,B'}$ y diremos que es la matriz \emph{asociada} a $T$.

La idea es análoga al de cambio de base, dado que $[v_i] = e_i$ y $T_{B,B'}e_i = (T_{B,B''})_{*i}$ para todo $i \in \{1,\ldots,n\}$, como $T_{B,B''}[v]_B = [T(v)]_{B'}$ para todo $v \in V$, entonces tenemos que
  \[ T_{B,B'} [v_i]_B = T_{B,B'} e_i = (T_{B,B'})_{*i} = [T(v_i)]_{B'}. \]
Así vemos que $[T(v_i)]_{B'}$ es la $i$-ésima columna de la matriz $T_{B,B'}$, y por lo tanto
  \[ T_{B,B'} = \begin{spmatrix}{c|c|c}  [T(v_1)]_{B'} & \cdots & [T(v_n)]_{B'}  \end{spmatrix}. \]

\begin{teor}
  Sean $V$ y $W$ dos $\F$-espacio vectorial con bases ordenadas $B = (v_1,\ldots,v_n)$ y $W' = (w_1,\ldots,w_m)$, respectivamente, y sea $T\colon V \to W$ una transformación lineal, entonces existe una única matriz $T_{B,B'}$ de tamaño $m\times n$ tal que para toda $v \in V$ se cumple que
    \[ T_{B,B'} [v]_B = [T(v)]_{B'} \]
  Además $(T_{B,B'})_{*i} = [T(v_i)]_{B'}$ para todo $i \in \{1,\ldots,n\}$.
\end{teor}
\begin{proof}
  Por el análisis hecho con anterioridad y definición, se cumple que
  \[ T_{B,B'} [v_i]_B = T_{B,B'} e_i = (T_{B,B'})_{*i} = [T(v_i)]_{B'}. \]
  
  De este modo sea $v \in V$ tal que $[v]_B = (\lambda_1,\ldots,\lambda_n)^t$, por la linealidad de $[\cdot]_B$ y las propiedades de las matrices, tenemos que
  \begin{align*}
    T_{B,B'}[v]_B &= T_{B,B'}[\lambda_1v_1 + \cdots + \lambda_n v_n]_B \\
      &= \lambda_1 T_{B,B'} [v_1]_B + \cdots + \lambda_n T_{B,B'} [v_n]_B \\
      &= \lambda_1 [T(v_1)]_{B'} + \cdots + \lambda_n [T(v_n)]_{B'} \\
      &= [T(\lambda v_1  + \cdots + \lambda_n v_n )]_{B'} \\
      &= [T(v)]_{B'}.
  \end{align*}
  Así tenemos que $T_{B,B'} [v]_B = [T(v)]_{B'}$ toda $v \in V$. Ahora, supongamos que existe otra matriz $P$ con la misma propiedad. Por el análisis del principio, para toda $i \in \{1,\ldots,n\}$ tenemos que
  \[ (T_{B,B'})_{*i} = [T(v_i)]_B = P[v_i]_B = Pe_i = P_{*i}, \]
  y dado que todas sus columnas son iguales, es claro que $P = T_{B,B'}$.
\end{proof}

Una consecuencia directa de este teorema, es que si consideramos las bases canónicas de $\F^n$ y $\F^m$, entonces toda transformación lineal $T\colon \F^n \to \F^m$ es de la forma $T(v) = M_T v$ donde
  \[ M_T = \begin{spmatrix}{c|c|c} T(e_i) & \cdots & T(e_n) \end{spmatrix}, \]
mostrando que toda transformación lineal es inducida por alguna matriz.

\begin{teor}\label{teo:isomTrMat}
  Sean $V$ y $W$ dos $\F$-espacio vectorial con bases ordenadas $B = (v_1,\ldots,v_n)$ y $W' = (w_1,\ldots,w_m)$. Si si consideramos la función $\Psi_{B,B'}\colon L(V,W) \to \M_{m\times n}(\F)$ dada por $\Psi_{B,B'}(T) = T_{B,B'}$, entonces $\Psi_{B,B'}$ es un isomorfismo de $V$ y $W$.
\end{teor}
\begin{proof}
  Primero demostremos que la función $\Psi_{B,B'}$ es una transformación lineal. Sean $T, S \in L(V,W)$ y $\lambda \in \F$, notemos que para todo $v \in V$ se cumple que
  \begin{align*}
    (T_{B,B'} + \lambda S_{B,B'})[v]_B &= T_{B,B'}[v]_B + \lambda S_{B,B'} [v]_B \\
      &= [T(v)]_{B'} + \lambda [S(v)]_{B'} \\
      &= [T(v) + \lambda S(v)]_{B'} \\
      &= [ (T + \lambda S)(v)]_{B'}.
  \end{align*}
  Pero por la unicidad de la matriz asociada, esto implica que $(T + \lambda S)_{B,B'} = T_{B,B'} + \lambda S_{B,B'}$, en otras palabras, que
  \[ \Psi_{B,B'}(T + \lambda S) = \Psi_{B,B'}(T) + \lambda \Psi_{B,B'}(S). \]

  Ahora, notemos que si $\Psi_{B,B'}(T) = \bec 0_{m\times n}$, entonces, por el teorema anterior, tenemos para todo $v \in V$ que  
    \[ T_{B,B'}[v]_B  = [T(v)]_{B'} = \bec 0_m,\]
  pero por propiedades conocidas sabemos que $[v]_{B'} = \bec 0_m$ si y solo si $v = 0_W$, de esta forma $T(v) = 0_W$, pero esto implica que $\ker(\Psi_{B,B'}) = \{  0_{L(V,W)} \}$, mostrando así que $\Psi_{B,B'}$ es inyectiva.

  Por ultimo, si $P \in \M_{m\times n}(\F)$ donde $P = (p_{ij})$, dado que podemos definir una transformación lineal únicamente dando los valores para una base, consideremos la transformación $T\colon V \to W$ dada por
  \[ T(v_i) =  p_{1i}w_1 + \cdots + p_{mi}w_m, \]
  para todo $i \in \{1,\ldots,m\}$. Aplicando el teorema anterior tenemos que $T_{B,B'} = P$, de este modo $\Psi_{B,B'}(T) = P$, mostrando así que $\Psi_{B,B'}$ es sobreyectiva y por tanto un isomorfismo de $L(V,W)$ a $\M_{m\times n}(\F)$.
\end{proof}

La relación de las matrices y las transformaciones lineales va más allá de que sean isomorfos como espacios vectoriales, además existe una relación entre la multiplicación de matrices y la composición de transformaciones lineales.

\begin{teor}
  Sean $V$, $W$ y $U$ tres $\F$-espacios vectoriales con bases ordenadas $B = (v_1,\ldots,v_n)$, $B' = (w_1,\ldots,w_m)$ y $B'' = (u_1,\ldots,u_p)$. Si $T\colon V \to W$ y $S\colon W \to W$ son transformaciones lineales, entonces
  \[ (S \circ T)_{B,B''} = S_{B',B''} T_{B,B'}. \]
\end{teor}
\begin{proof}
  Sea $v \in V$, notemos que por definición que
    \begin{align*}
      S_{B',B''} T_{B,B'}[v_B] &= S_{B',B''}[T(v)]_{B'} \\
        &= \bigl[ S\bigl(T(v)\bigr) \bigr]_{B''} \\
        &= [(S\circ T)(v)]_{B''}.
    \end{align*}
  Pero por la unicidad de la matriz asociada, esto implica que $(S \circ T)_{B,B''} = S_{B',B''} T_{B,B'}$.
\end{proof}

\begin{coro}
  Sean $V$ y $W$ dos $\F$-espacios vectoriales con bases ordenadas $B = (v_1,\ldots,v_n)$ y $W' = (w_1,\ldots,w_m)$, respectivamente, y sea $T\colon V \to W$ una transformación lineal, entonces $T$ es invertible si y solo si $T_{B,B'}$ es invertible, además
    \[ T_{B',B}^{-1} = (T_{B,B'})^{-1}. \]
\end{coro}
\begin{proof}
  Dado que $T$ es invertible entonces es biyectiva, por lo que $m = n$. Así, por el teorema anterior, tenemos que
  \[ T^{-1}_{B',B} T_{B,B'} = (T^{-1}\circ T)_{B,B} = (\Id_{V,W})_{B,B} = I_n, \]
  pero esto impĺica que $T_{B',B}^{-1} = (T_{B,B'})^{-1}$, por definición.

  Ahora, si $T_{B,B'}$ es invertible entonces $m = n$ y por el teorema \ref{teo:isomTrMat} existe una transformación lineal $S\colon W \to V$ tal que $S_{B',B} =  (T_{B,B'})^{-1}$. Aplicando el teorema anterior, esto implica que
    \[ (S \circ T)_{B,B} =  S_{B',B}T_{B,B'} = I_n = (\Id_{V,W})_{B,B}. \]
  De nuevo, por el teorema \ref{teo:isomTrMat}, tenemos que $S \circ T = \Id_{V,W}$ y análogamente se tiene que $T \circ S = \Id_{V,W}$, mostrando así que $T$ es invertible.
\end{proof}



\section{Semejanza de matrices}

Hemos visto que podemos asociar una matriz a cada transformación siempre que definamos unas bases ordenadas. Sl siguiente paso, es ver como obtener la matriz asociada de la misma transformación pero con bases diferentes. Esto lo haremos con la matriz de cambio de base.

\begin{teor}
  Sea $V$ y $W$ dos $\F$-espacios vectoriales y $T \colon V \to W$ una transformación lineal. Si $B_1$ y $B_2$ son bases ordenadas de $V$, $B_1'$ y $B_2'$ son bases ordenadas de $W$ entonces
  \[T_{B_2,B_2'} = M_{B_1', B_2'} T_{B_1,B_1'}M_{B_2,B_1}. \]
\end{teor}
\begin{proof}
  Sea $v \in V$, notemos, por definición y propiedades conocidas, que
  \begin{align*}
    M_{B_1', B_2'} T_{B_1,B_1'}M_{B_2,B_1} [v]_{B_2} &= M_{B_1', B_2'} T_{B_1,B_1'} [v]_{B_1} \\
      &= M_{B_1', B_2'} [T(v)]_{B_1'} \\
      &= [T(v)]_{B_2'}.
  \end{align*}
  Y por la unicidad de la matriz asociada, tenemos que $T_{B_2,B_2'} = M_{B_1', B_2'} T_{B_1,B_1'}M_{B_2,B_1}$.
\end{proof}

Notemos que en el teorema anterior las matrices $T_{B_1,B_1'}$ y $T_{B_2,B_2'}$ son distintas, pero que son matrices asociadas a la misma transformación. Lo mismo ocurre con con la matriz de cambio de base, notemos que si $B$ y $B$ son os bases ordenadas de $V$ entonces $[\Id_V]_{B,B'}[v]_B = [v]_B'$ por lo tanto $[\Id_V]_{B,B'} = M_{B,B'}$, dado que todas las matrices invertibles son de cambio de base, eso quiere decir que todas las matrices invertible están asociada a la transformación identidad, bajo unas ciertas bases.

Esta idea se puede generalizar, si $V$ y $W$ son $\F$-espacios vectoriales con bases ordenadas $B_1$ y $B_1'$, respectivamente, y $T\colon V \to W$ es una transformación lineal, si $M = PT_{B,B'}Q$ donde $P$ y $Q$ son dos matrices invertibles, por la proposición \ref{prop:ExBase} y el teorema anterior existirán bases ordenadas $B_2$ y $B_2'$ de $V$ y $W$, respectivamente, tal que $M = T_{B_2, B_2'}$. Esto quiere decir que todas las matrices de la forma $PT_{B,B'}Q$, donde $P$ y $Q$ son dos matrices invertibles, están asociadas a $T$.

Un caso de especial interés son las matrices asociadas cuando $T$ es un endomorfismo de $V$ sobre la misma base. Si $B$ es una base ordenada de $V$, definiremos $T_B = T_{B,B}$. Notemos que si deseamos obtener $T_{B'}$, dado que $M_{B,B'} = (M_{B',B})^{-1}$ entonces 
  \[ T_{B'} = (M_{B',B})^{-1} T_B M_{B',B} \]
y de nuevo,por la proposición \ref{prop:ExBase} podemos ver que todas las matrices $P^{-1}T_{B}P$, donde $P$ es una matriz invertible, están asociadas a la misma transformación. De esta forma, la meta será agrupar todas las matrices que están asociadas a una misma transformación lineal.

\begin{defi}
  Sean $M$ y $N$ dos matrices de $n \times n$ con elementos en $\F$, se dice que $M$ es \emph{semejante} a $N$ si existe una matriz invertible $P$ tal que $M = P^{-1}NP$, y lo denotaremos como $M \sim N$.
\end{defi}

\begin{prop}
  Sean $M,N \in \M_n(\F)$ tal que $M \sim N$, entonces $\det(M) = \det(N)$ y $\tr(M) = \tr(N)$.
\end{prop}
\begin{proof}
  Por definición, existe una matriz invertible $P$ tal que $M = P^{-1}NP$. La primera igualdad es fácil de probar, ya que por por propiedad de la determinante tenemos  que
  \begin{align*}
    \det(M) &= \det(P^{-1}NP) = \det(P^{-1})\det(N) \det(P)  \\
      &= \bigl(\det(P)\bigr)^{-1} \det(N) \det(P) = \bigl(\det(P)\bigr)^{-1}\det(P)\det(N)  \\
      &= \det(N).
  \end{align*}
  
  Para la segunda propiedad, notemos que si $A,B \in \M_n(\F)$ dado por $A = (a_{ij})$ y $B = (b_{ij})$ entonces
  \begin{align*}
    \tr(AB) &= \sum_{i=1}^n (AB)_{ii} = \sum_{i=1}^n \sum_{j=1}^n a_{ij} b_{ji} \\
      &=  \sum_{j=1}^n \sum_{i=1}^n b_{ji} a_{ij} = \sum_{j=1}^n (BA)_{jj} \\
      &= \tr(BA).
  \end{align*}
  De esta forma, tenemos que por definición y la propiedad anterior
  \[ \tr(M) = \tr(P^{-1}NP) = \tr([P^{-1}N]P) = \tr(P[P^{-1}N]) = \tr(I_n N) = \tr(N). \]
\end{proof}

Esta propiedad nos muestra que todas las matrices asociadas a una transformación lineal tienen la misma determinante y traza, en otras palabras, la traza y determinante son invariantes ante el cambio de base.